# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YBlap_c1BCQp8R0X7UUO5EYsu_VoJk0b
"""

!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip -P /resources/data

!unzip -q  /resources/data/concrete_crack_images_for_classification.zip -d  /resources/data

from PIL import Image
import matplotlib.pyplot as plt
import os
import glob
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torch.nn as nn
from torch import optim

class Dataset(Dataset):

    # Constructor
    def __init__(self,transform=None,train=True):
        directory="/resources/data"
        positive="Positive"
        negative="Negative"

        positive_file_path=os.path.join(directory,positive)
        negative_file_path=os.path.join(directory,negative)
        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(".jpg")]
        positive_files.sort()
        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(".jpg")]
        negative_files.sort()
        number_of_samples=len(positive_files)+len(negative_files)
        self.all_files=[None]*number_of_samples
        self.all_files[::2]=positive_files
        self.all_files[1::2]=negative_files 
        # The transform is goint to be used on image
        self.transform = transform
        #torch.LongTensor
        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)
        self.Y[::2]=1
        self.Y[1::2]=0
        
        if train:
            self.all_files=self.all_files[0:30000]
            self.Y=self.Y[0:30000]
            self.len=len(self.all_files)
        else:
            self.all_files=self.all_files[30000:]
            self.Y=self.Y[30000:]
            self.len=len(self.all_files)    
       
    # Get the length
    def __len__(self):
        return self.len
    
    # Getter
    def __getitem__(self, idx):
        image=Image.open(self.all_files[idx])
        y=self.Y[idx]        
        # If there is any transform method, apply it onto the image
        if self.transform:
            image = self.transform(image)
        sample=image,y

        return sample

#transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
# transforms.ToTensor()
#transforms.Normalize(mean, std)
#transforms.Compose([])

transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])

dataset_train=Dataset(transform=transform,train=True)
dataset_val=Dataset(transform=transform,train=False)

dataset_train[0][0].shape
#dataset_train[0][1]

size_of_image=3*227*227
size_of_image

torch.manual_seed(0)

class Softmax(nn.Module):
    def __init__(self,input_size,output_size):
        super(Softmax,self).__init__()
        self.linear=nn.Linear(input_size,output_size)

    def forward(self,x):
        out=self.linear(x)
        return out

model=Softmax(input_size=size_of_image,output_size=2)

learning_rate=0.1
optimizer=optim.SGD(model.parameters(),lr=learning_rate,momentum=0.1)

criterion=nn.CrossEntropyLoss()   

train_loader=DataLoader(dataset=dataset_train,batch_size=1000)
validation_loader=torch.utils.data.DataLoader(dataset=dataset_val,batch_size=1000)

def train(data_set,model, criterion, train_loader, optimizer, epochs=5):
    LOSS = []
    ACC = []
    #correct=0
    for epoch in range(epochs):
        correct=0
        train_loss=0
        for image, label in train_loader:
            optimizer.zero_grad()
            z = model(image.view(-1,size_of_image))
            _, yhat = torch.max(z.data,1)
            correct=correct+(yhat == label).sum().item()
            loss = criterion(z, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss+=loss.item()
        accuracy=correct/dataset_train.len
        LOSS.append(train_loss/len(train_loader))       # LOSS.append(loss.item())
        ACC.append(accuracy)          #accuracy(model,data_set)
        
    results ={"Loss":LOSS, "Accuracy":ACC}
    fig, ax1 = plt.subplots()
    color = 'tab:red'
    ax1.plot(LOSS,color=color)
    ax1.set_xlabel('epoch', color=color)
    ax1.set_ylabel('total loss', color=color)
    ax1.tick_params(axis = 'y', color=color)
    
    ax2 = ax1.twinx()  
    color = 'tab:blue'
    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1
    ax2.plot(ACC, color=color)
    ax2.tick_params(axis='y', color=color)
    fig.tight_layout()  # otherwise the right y-label is slightly clipped
    
    plt.show()
    return results



A=train(dataset_train, model, criterion, train_loader, optimizer, epochs=5)
print(A)



